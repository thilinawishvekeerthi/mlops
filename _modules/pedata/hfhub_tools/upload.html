<!DOCTYPE html>
<html  lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
      <title>pedata.hfhub_tools.upload</title>
    
          <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
          <link rel="stylesheet" href="../../../_static/theme.css " type="text/css" />
      
      <!-- sphinx script_files -->
        <script src="../../../_static/documentation_options.js?v=834eaed7"></script>
        <script src="../../../_static/doctools.js?v=888ff710"></script>
        <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>

      
      <!-- bundled in js (rollup iife) -->
      <!-- <script src="../../../_static/theme-vendors.js"></script> -->
      <script src="../../../_static/theme.js" defer></script>
    
  <link rel="index" title="Index" href="../../../genindex.html" />
  <link rel="search" title="Search" href="../../../search.html" /> 
  </head>

  <body>
    <div id="app">
    <div class="theme-container" :class="pageClasses"><navbar @toggle-sidebar="toggleSidebar">
  <router-link to="../../../index.html" class="home-link">
    
      <span class="site-name">pedata documentation</span>
    
  </router-link>

  <div class="links">
    <navlinks class="can-hide">



    </navlinks>
  </div>
</navbar>

      
      <div class="sidebar-mask" @click="toggleSidebar(false)">
      </div>
        <sidebar @toggle-sidebar="toggleSidebar">
          
          <navlinks>
            



            
          </navlinks><div id="searchbox" class="searchbox" role="search">
  <div class="caption"><span class="caption-text">Quick search</span>
    <div class="searchformwrapper">
      <form class="search" action="../../../search.html" method="get">
        <input type="text" name="q" />
        <input type="submit" value="Search" />
        <input type="hidden" name="check_keywords" value="yes" />
        <input type="hidden" name="area" value="default" />
      </form>
    </div>
  </div>
</div><div class="sidebar-links" role="navigation" aria-label="main navigation">
  
    <div class="sidebar-group">
      <p class="caption">
        <span class="caption-text"><a href="../../../index.html#pedata-documentation">pedata documentation!</a></span>
      </p>
      <ul class="">
        
          <li class="toctree-l1 ">
            
              <a href="../../../pedata.html" class="reference internal ">pedata package</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="../../../pedata.encoding.html" class="reference internal ">pedata.encoding package</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="../../../pedata.config.html" class="reference internal ">pedata.config package</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="../../../pedata.mutation.html" class="reference internal ">pedata.mutation package</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="../../../modules.html" class="reference internal ">pedata</a>
            

            
          </li>

        
      </ul>
    </div>
  
</div>
        </sidebar>

      <page>
          <div class="body-header" role="navigation" aria-label="navigation">
  
  <ul class="breadcrumbs">
    <li><a href="../../../index.html">Docs</a> &raquo;</li>
    
      <li><a href="../../index.html">Module code</a> &raquo;</li>
    
    <li>pedata.hfhub_tools.upload</li>
  </ul>
  

  <ul class="page-nav">
</ul>
  
</div>
<hr>
          <div class="content" role="main" v-pre>
            
  <h1>Source code for pedata.hfhub_tools.upload</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot; #FIXME: THIS NEED FULL REFACTORING</span>
<span class="sd">Module upload.py</span>

<span class="sd">Usage from the command line:</span>

<span class="sd">    Required argument:</span>
<span class="sd">        --repo, Name of the repository on Hugging Face</span>
<span class="sd">        </span>
<span class="sd">    None required arguments:</span>
<span class="sd">        --commit_hash, Commit hash of the dataset to pull from Hugging Face. default=None,</span>
<span class="sd">        --filename, Path to the CSV file for dataset creation. default=None,</span>
<span class="sd">        --local_dir, Name of the local directory to save the dataset to. default=&quot;./local_datasets&quot;,</span>
<span class="sd">        --cache_dir, cache directory; default: &quot;./cache&quot;</span>
<span class="sd">        --save_locally, Name of the local directory to save the dataset to. default=True,</span>
<span class="sd">        --splits_to_combine_as_whole_ds, list: names of the split to combine as &#39;whole_dataset&#39; ex --splits_to_combine_as_whole_ds whole_dataset</span>
<span class="sd">        --update_just_readme, When update - just update the readme or dataset card. default=False,</span>
<span class="sd">        --needed_encodings, list: list of encodings for the dataset; ex --needed_encodings aa_seq aa_1hot</span>
<span class="sd">        --overwrite_repo, bool: Set to True to overwrite a repo when uploading a new dataset, if the repo already exists</span>


<span class="sd">Examples: </span>
<span class="sd">    Uploading a new dataset from a csv file to a new repo</span>
<span class="sd">    ```bash</span>
<span class="sd">    &quot;python src/pedata/Company_datasets/upload.py --repo Company/test_example_dataset_ha1 --filename local_datasets/datafiles/example_dataset_ha1.csv --needed_encodings &#39;aa_seq&#39; &#39;aa_1hot&#39; &#39;aa_unirep_1900&#39;</span>
<span class="sd">    ```</span>

<span class="sd">    Overwriting a new repo by uploading a new dataset made from a csv file</span>
<span class="sd">    ```bash</span>
<span class="sd">    python src/pedata/Company_datasets/upload.py ... same as above ... --overwrite_repo True &quot;</span>
<span class="sd">    ```</span>

<span class="sd">    Pulling a dataset from huggingface, updating it and uploading it uploading to the same repo</span>
<span class="sd">    ```bash</span>
<span class="sd">    &quot;python src/pedata/Company_datasets/upload.py --repo Company/test_example_dataset_ha1&quot;</span>

<span class="sd">```</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># FIXME: refactor this as a upload and update class -</span>
<span class="c1"># create a pipeline which includes</span>
<span class="c1"># - checking the dataset,</span>
<span class="c1"># - adding encodigns,</span>
<span class="c1"># - adding index,</span>
<span class="c1"># - adding splits</span>
<span class="c1"># - execute tag_finder</span>
<span class="c1"># - save the data locally</span>
<span class="c1"># - (delete the data from the hub - only if update)</span>
<span class="c1"># - push the data to the hub</span>
<span class="c1"># - update the readme -&gt; check the function from huggingface to update the metadata</span>
<span class="c1"># - push the readme to the hub</span>

<span class="c1"># setting setting the __package__ attribute to solve the relative import proplem when runningn the scripts in the command line</span>
<span class="n">__package__</span> <span class="o">=</span> <span class="s2">&quot;pedata.hfhub_tools&quot;</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Sequence</span>
<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span><span class="p">,</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">concatenate_datasets</span>
<span class="kn">from</span> <span class="nn">huggingface_hub</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">repo_exists</span><span class="p">,</span>
    <span class="n">list_repo_files</span><span class="p">,</span>
    <span class="n">delete_file</span><span class="p">,</span>
    <span class="n">metadata_update</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">..transform</span> <span class="kn">import</span> <span class="n">transform_pipeline</span>
<span class="kn">from</span> <span class="nn">..disk_cache</span> <span class="kn">import</span> <span class="n">preprocess_data</span>
<span class="kn">from</span> <span class="nn">..util</span> <span class="kn">import</span> <span class="n">get_target</span>
<span class="kn">from</span> <span class="nn">..visual</span> <span class="kn">import</span> <span class="n">plot_target_distributions</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">ReadMe</span>

<div class="viewcode-block" id="DatasetUpload">
<a class="viewcode-back" href="../../../pedata.hfhub_tools.html#pedata.hfhub_tools.upload.DatasetUpload">[docs]</a>
<span class="k">class</span> <span class="nc">DatasetUpload</span><span class="p">:</span>  <span class="c1"># FIXME: change the name of this class</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A class to handle dataset creation, update and upload to Hugging Face Hub.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="DatasetUpload.__init__">
<a class="viewcode-back" href="../../../pedata.hfhub_tools.html#pedata.hfhub_tools.upload.DatasetUpload.__init__">[docs]</a>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">repo</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">commit_hash</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">local_dir</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">Path</span> <span class="o">=</span> <span class="s2">&quot;./local_datasets&quot;</span><span class="p">,</span>
        <span class="n">cache_dir</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">Path</span> <span class="o">=</span> <span class="s2">&quot;./cache&quot;</span><span class="p">,</span>
        <span class="n">csv_filename</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">Path</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">save_locally</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">splits_to_combine_as_whole_ds</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="p">[],</span>
        <span class="n">update_just_readme</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">needed_encodings</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[],</span>
        <span class="n">overwrite_repo</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the class and run the creation, update and upload pipeline.</span>
<span class="sd">        Args:</span>
<span class="sd">            repo (str): Hugging Face Hub repository name (format: &#39;Company/dataset-name&#39;).</span>
<span class="sd">            local_dir (str): Local directory to save the dataset to.</span>
<span class="sd">            cache_dir (str): cache directory</span>
<span class="sd">            csv_filename (str): Path to the CSV file for dataset creation.</span>
<span class="sd">                if None, the dataset is pulled from Hugging Face Hub and updated. - default: None</span>
<span class="sd">            save_locally (bool): Whether to save the dataset to a local directory. - default: True</span>
<span class="sd">            splits_to_combine_as_whole_ds: The name of the splits to combine as the whole dataset</span>
<span class="sd">                - when updating a dataset which is already on the hub. - default: []</span>
<span class="sd">            update_just_readme (bool): When updating a dataset which is already on the hub,</span>
<span class="sd">                update just the readme or dataset card. - default: False</span>
<span class="sd">            needed_encodings (list): list of encodings for the dataset; default: []</span>
<span class="sd">            overwrite_repo (bool): Set to True to overwrite a repo when uploading a new dataset,</span>
<span class="sd">                if the repo already exists - default: False</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_repo</span> <span class="o">=</span> <span class="n">repo</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_commit_hash</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">commit_hash</span><span class="p">)</span> <span class="k">if</span> <span class="n">commit_hash</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_local_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">local_dir</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">local_dir</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">local_dir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cache_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">cache_dir</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cache_dir</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">cache_dir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_csv_filename</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">Path</span><span class="p">(</span><span class="n">csv_filename</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">csv_filename</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">csv_filename</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_save_locally</span> <span class="o">=</span> <span class="n">save_locally</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_whole_split_name</span> <span class="o">=</span> <span class="s2">&quot;whole_dataset&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_splits_to_combine_as_whole_ds</span> <span class="o">=</span> <span class="n">splits_to_combine_as_whole_ds</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_just_readme</span> <span class="o">=</span> <span class="n">update_just_readme</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_needed_encodings</span> <span class="o">=</span> <span class="n">needed_encodings</span>  <span class="c1"># TODO - add a setter for this</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init_process</span><span class="p">(</span><span class="n">overwrite_repo</span><span class="p">)</span></div>


    <span class="k">def</span> <span class="nf">_init_process</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">overwrite_repo</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_csv_filename</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">repo_exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_repo</span><span class="p">,</span> <span class="n">repo_type</span><span class="o">=</span><span class="s2">&quot;dataset&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">overwrite_repo</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;repo </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_repo</span><span class="si">}</span><span class="s2"> already exists </span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="s2">&quot;Please choose another name or set overwrite_repo=True to overwrite the content of the repo&quot;</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_and_preprocess</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_csv_filename</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_needed_encodings</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pull_and_update</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_repo</span><span class="p">,</span>
                <span class="n">commit_hash</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_commit_hash</span><span class="p">,</span>
                <span class="n">whole_split_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_whole_split_name</span><span class="p">,</span>
                <span class="n">splits_to_combine_as_whole_ds</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_splits_to_combine_as_whole_ds</span><span class="p">,</span>
                <span class="n">update_just_readme</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_update_just_readme</span><span class="p">,</span>
                <span class="n">needed_encodings</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_needed_encodings</span><span class="p">,</span>
                <span class="n">cache_dir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_cache_dir</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">local_path</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_local_dir</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repo</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">figure_path</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">local_path</span><span class="p">,</span> <span class="s2">&quot;figures&quot;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">cache_dir</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cache_dir</span>

<div class="viewcode-block" id="DatasetUpload.process">
<a class="viewcode-back" href="../../../pedata.hfhub_tools.html#pedata.hfhub_tools.upload.DatasetUpload.process">[docs]</a>
    <span class="k">def</span> <span class="nf">process</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">readme</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run the creation, update and upload pipeline.</span>
<span class="sd">        FIXME - from Ingmar: the usage of this class I&#39;ve always seen only creation of an object directly followed by a call to this method. If this is the only usage then a simple function definition / function call would be better.</span>
<span class="sd">        If the class definition makes implementation better/easier to understand, then this would only mean changing the API, e.g. by introducing a small wrapper function</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="fm">__repr__</span><span class="p">())</span>

        <span class="c1"># create local directory</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">local_path</span><span class="p">):</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">local_path</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">readme</span><span class="p">:</span>
            <span class="c1"># create the figures directory</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">local_path</span><span class="si">}</span><span class="s2">/figures&quot;</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># save</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_save_locally</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_path</span><span class="p">)</span>

        <span class="c1"># cleanup hub before pushing (only when updating)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_csv_filename</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># clear the datafiles in the repo</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_clear_hub_dataset_files</span><span class="p">()</span>

            <span class="c1"># update the metadata in the dataset card with nothing in it</span>
            <span class="n">metadata_update</span><span class="p">(</span>
                <span class="n">repo_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_repo</span><span class="p">,</span>
                <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;dataset_info&quot;</span><span class="p">:</span> <span class="s2">&quot;nothing in it&quot;</span><span class="p">,</span> <span class="s2">&quot;configs&quot;</span><span class="p">:</span> <span class="p">[]},</span>
                <span class="n">repo_type</span><span class="o">=</span><span class="s2">&quot;dataset&quot;</span><span class="p">,</span>
                <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># clear the cache before pushing</span>
        <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cache_dir</span><span class="p">,</span> <span class="n">ignore_errors</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># push</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">push</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span><span class="p">,</span> <span class="n">repo</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_repo</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_whole_split_name</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="fm">__repr__</span><span class="p">())</span>

        <span class="k">if</span> <span class="n">readme</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update_readme</span><span class="p">()</span>

        <span class="c1"># clear the cache</span>
        <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cache_dir</span><span class="p">,</span> <span class="n">ignore_errors</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></div>


<div class="viewcode-block" id="DatasetUpload.make_read_me_figures">
<a class="viewcode-back" href="../../../pedata.hfhub_tools.html#pedata.hfhub_tools.upload.DatasetUpload.make_read_me_figures">[docs]</a>
    <span class="k">def</span> <span class="nf">make_read_me_figures</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">plot_target_distributions</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">targets</span><span class="p">,</span> <span class="n">savedir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">local_path</span><span class="p">)</span></div>


<div class="viewcode-block" id="DatasetUpload.update_readme">
<a class="viewcode-back" href="../../../pedata.hfhub_tools.html#pedata.hfhub_tools.upload.DatasetUpload.update_readme">[docs]</a>
    <span class="k">def</span> <span class="nf">update_readme</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Update the readme file&quot;&quot;&quot;</span>
        <span class="n">readme</span> <span class="o">=</span> <span class="n">ReadMe</span><span class="p">(</span><span class="n">local_dir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">local_path</span><span class="p">)</span>
        <span class="n">readme</span><span class="o">.</span><span class="n">pull_readme_from_hub</span><span class="p">(</span><span class="n">repo_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_repo</span><span class="p">)</span>

        <span class="n">readme</span><span class="o">.</span><span class="n">update_readme</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datapoints_n</span><span class="p">,</span> <span class="s2">&quot;datapoints&quot;</span><span class="p">)</span>
        <span class="n">readme</span><span class="o">.</span><span class="n">update_readme</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">,</span> <span class="s2">&quot;embeddings&quot;</span><span class="p">)</span>
        <span class="n">readme</span><span class="o">.</span><span class="n">update_readme</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_names</span><span class="p">,</span> <span class="s2">&quot;targets&quot;</span><span class="p">)</span>
        <span class="n">readme</span><span class="o">.</span><span class="n">update_readme</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">available_splits</span><span class="p">,</span> <span class="s2">&quot;available_splits&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">make_read_me_figures</span><span class="p">()</span>

        <span class="n">readme</span><span class="o">.</span><span class="n">update_readme_figures</span><span class="p">(</span><span class="n">figure_path</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">figure_path</span><span class="p">)</span>
        <span class="n">readme</span><span class="o">.</span><span class="n">push_figures_to_hub</span><span class="p">()</span>
        <span class="n">readme</span><span class="o">.</span><span class="n">push_readme_to_hub</span><span class="p">(</span><span class="n">repo_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_repo</span><span class="p">)</span></div>


    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Print the processing to be done or the processing done.&quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">print_list</span><span class="p">(</span><span class="n">l</span><span class="p">):</span>
            <span class="k">return</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="sa">f</span><span class="s2">&quot; - </span><span class="si">{</span><span class="n">item</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">l</span><span class="p">])</span>
        <span class="k">if</span> <span class="s2">&quot;_dataset&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">:</span>
            <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">------------------------------------</span>
<span class="s2">DatasetUpload - Processing to be done</span>
<span class="s2">------------------------------------</span>
<span class="s2">- repo=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_repo</span><span class="si">}</span><span class="s2"> </span>
<span class="s2">- local_dir=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_local_dir</span><span class="si">}</span>
<span class="s2">- csv_filename=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_csv_filename</span><span class="si">}</span>
<span class="s2">- save_locally=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_save_locally</span><span class="si">}</span>
<span class="s2">            &quot;&quot;&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">-------------------------------</span>
<span class="s2">DatasetUpload - Processing done</span>
<span class="s2">-------------------------------</span>
<span class="s2">Saved locally: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">local_path</span><span class="si">}</span>
<span class="s2">Pushed to the huggingface repository: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_repo</span><span class="si">}</span>
<span class="s2">Available features:</span>
<span class="si">{</span><span class="n">print_list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span><span class="si">}</span>
<span class="s2">Available targets: </span>
<span class="si">{</span><span class="n">print_list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_names</span><span class="p">)</span><span class="si">}</span>
<span class="s2">Available splits:</span>
<span class="si">{</span><span class="n">print_list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">available_splits</span><span class="p">)</span><span class="si">}</span>
<span class="s2">            &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">target_names</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;get all target names&quot;&quot;&quot;</span>
        <span class="n">targets</span> <span class="o">=</span> <span class="n">get_target</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span><span class="p">,</span> <span class="n">as_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">targets</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Getting all targets</span>
<span class="sd">        Returns:</span>
<span class="sd">            Dictionary of targets with the target names as keys and the target values as values</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">get_target</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span><span class="p">,</span> <span class="n">as_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">available_splits</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;get all available splits&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span><span class="o">.</span><span class="n">column_names</span> <span class="k">if</span> <span class="s2">&quot;split&quot;</span> <span class="ow">in</span> <span class="n">col</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">feature_names</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;get all features names&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="n">col</span>
            <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span><span class="o">.</span><span class="n">column_names</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span>
                <span class="n">col</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_names</span>
                <span class="ow">or</span> <span class="n">col</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">available_splits</span>
                <span class="ow">or</span> <span class="n">col</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;index&quot;</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">datapoints_n</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;get the number of datapoints&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span><span class="o">.</span><span class="n">num_rows</span><span class="p">]</span>

<div class="viewcode-block" id="DatasetUpload.create_and_preprocess">
<a class="viewcode-back" href="../../../pedata.hfhub_tools.html#pedata.hfhub_tools.upload.DatasetUpload.create_and_preprocess">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">create_and_preprocess</span><span class="p">(</span>
        <span class="n">csv_filename</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">Path</span><span class="p">,</span> <span class="n">needed_encodings</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a dataset from a CSV file and push it to Hugging Face.</span>
<span class="sd">        Args:</span>
<span class="sd">            filename (str): Path to the CSV file.</span>
<span class="sd">            needed_encodings: list of encodings</span>
<span class="sd">        Returns:</span>
<span class="sd">            ds.Dataset: Dataset created from the CSV file.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Convert CSV to Hugging Face dataset</span>
        <span class="k">return</span> <span class="n">preprocess_data</span><span class="p">(</span>
            <span class="n">csv_filename</span><span class="p">,</span>
            <span class="n">add_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">add_splits</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">needed_encodings</span><span class="o">=</span><span class="n">needed_encodings</span><span class="p">,</span>
        <span class="p">)</span></div>


        <span class="c1"># print(f&quot;Dataset &#39;{repo}&#39; successfully pushed to Hugging Face.&quot;)</span>

<div class="viewcode-block" id="DatasetUpload.pull_and_update">
<a class="viewcode-back" href="../../../pedata.hfhub_tools.html#pedata.hfhub_tools.upload.DatasetUpload.pull_and_update">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pull_and_update</span><span class="p">(</span>
        <span class="n">repo</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">commit_hash</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">whole_split_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;whole_dataset&quot;</span><span class="p">,</span>
        <span class="n">splits_to_combine_as_whole_ds</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="p">[],</span>
        <span class="n">update_just_readme</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">needed_encodings</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[],</span>
        <span class="n">cache_dir</span><span class="o">=</span><span class="s2">&quot;./cache&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Pull a dataset from Hugging Face, update it.</span>
<span class="sd">        Args:</span>
<span class="sd">            repo (str): Hugging Face Hub repository name (format: &#39;Company/dataset-name&#39;).</span>
<span class="sd">        returns:</span>
<span class="sd">            ds.Dataset: Dataset pulled from Hugging Face.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Pull dataset from Hugging Face</span>
        <span class="c1"># concatenate_datasets makes sure that the dataset is a dataset and not a dataset dictionary (which is the case when pulling from the hub)</span>
        <span class="n">dataset_dict</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">repo</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">download_mode</span><span class="o">=</span><span class="s2">&quot;force_redownload&quot;</span><span class="p">,</span>
            <span class="n">cache_dir</span><span class="o">=</span><span class="n">Path</span><span class="p">(</span><span class="n">cache_dir</span><span class="p">),</span>
            <span class="n">revision</span><span class="o">=</span><span class="n">commit_hash</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">splits_already_in_dataset</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">dataset_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="c1"># return the dataset in the a dataset dictionary with the whole dataset as one split named &#39;whole_dataset&#39;</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset_dict</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">whole_split_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">splits_already_in_dataset</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;DatasetDict has more than one split and does not have a split named </span><span class="si">{</span><span class="n">whole_split_name</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="s2">&quot;Use splits_to_combine_as_whole_ds as argument to specify which splits to combine.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># if splits_to_combine_as_whole_ds and there is only one split in the dataset</span>
        <span class="k">if</span> <span class="n">splits_to_combine_as_whole_ds</span> <span class="o">==</span> <span class="p">[]</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset_dict</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">splits_to_combine_as_whole_ds</span> <span class="o">=</span> <span class="n">splits_already_in_dataset</span>

        <span class="c1"># convert the DatasetDict to a Dataset</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">concatenate_datasets</span><span class="p">(</span>
            <span class="p">[</span><span class="n">dataset_dict</span><span class="p">[</span><span class="n">ds</span><span class="p">]</span> <span class="k">for</span> <span class="n">ds</span> <span class="ow">in</span> <span class="n">splits_to_combine_as_whole_ds</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">update_just_readme</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">dataset</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">transform_pipeline</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">needed_encodings</span><span class="p">)</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">files_in_repo</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get all files in a HuggingFace dataset repository folder.</span>
<span class="sd">        Args:</span>
<span class="sd">            repo : Hugging Face Hub repository name (format: &#39;Company/dataset-name&#39;).</span>
<span class="sd">        Returns:</span>
<span class="sd">            list: List of files in the data/ folder of the repository.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">list_repo_files</span><span class="p">(</span><span class="n">repo_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_repo</span><span class="p">,</span> <span class="n">repo_type</span><span class="o">=</span><span class="s2">&quot;dataset&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_hub_data_folder_files</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get all files in a HuggingFace dataset repository data/ folder.</span>
<span class="sd">        Args:</span>
<span class="sd">            repo : Hugging Face Hub repository name (format: &#39;Company/dataset-name&#39;).</span>
<span class="sd">        Returns:</span>
<span class="sd">            list: List of files in the data/ folder of the repository.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">file</span> <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">files_in_repo</span> <span class="k">if</span> <span class="s2">&quot;data/&quot;</span> <span class="ow">in</span> <span class="n">file</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_repo_get_file_list_split_cleanup</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Delete all files in a HuggingFace dataset repository.</span>
<span class="sd">        Checks the difference between the list of files in the repo and the list of files in the dataset directory using the load_dataset methods.</span>
<span class="sd">        Args:</span>
<span class="sd">            repo : Hugging Face Hub repository name (format: &#39;Company/dataset-name&#39;).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dataset_files</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_hub_data_folder_files</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">dataset_files</span> <span class="o">==</span> <span class="p">[]:</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="n">dataset_dict_keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">load_dataset</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_repo</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">list_of_files_to_delete</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># FIXME write this as a list comprehension</span>
        <span class="k">for</span> <span class="n">dataset_dict_key</span> <span class="ow">in</span> <span class="n">dataset_dict_keys</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">dataset_file</span> <span class="ow">in</span> <span class="n">dataset_files</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">dataset_dict_key</span> <span class="ow">in</span> <span class="n">dataset_file</span><span class="p">:</span>
                    <span class="n">list_of_files_to_delete</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dataset_file</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">list_of_files_to_delete</span>

    <span class="k">def</span> <span class="nf">_clear_hub_dataset_files</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">list_of_files_to_delete</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="p">[])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Delete all files in a HuggingFace dataset repository data/ folder.</span>
<span class="sd">        Args:</span>
<span class="sd">            dataset (ds.Dataset): Dataset to save and push.</span>
<span class="sd">            list_of_files_to_delete (list): List of files to delete from the hub.</span>
<span class="sd">                default: [] -&gt; delete all datafiles not corresponding to the splits present in self.dataset</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">list_of_files_to_delete</span> <span class="o">==</span> <span class="p">[]:</span>
            <span class="n">list_of_files_to_delete</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repo_get_file_list_split_cleanup</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">list_of_files_to_delete</span> <span class="o">!=</span> <span class="p">[]:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">list_of_files_to_delete</span><span class="si">}</span><span class="s2"> will be deleted from </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_repo</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">file_to_delete</span> <span class="ow">in</span> <span class="n">list_of_files_to_delete</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Deleting </span><span class="si">{</span><span class="n">file_to_delete</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">delete_file</span><span class="p">(</span>
                    <span class="n">path_in_repo</span><span class="o">=</span><span class="n">file_to_delete</span><span class="p">,</span>
                    <span class="n">repo_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_repo</span><span class="p">,</span>
                    <span class="n">repo_type</span><span class="o">=</span><span class="s2">&quot;dataset&quot;</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;No dataset files to delete from </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_repo</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<div class="viewcode-block" id="DatasetUpload.save">
<a class="viewcode-back" href="../../../pedata.hfhub_tools.html#pedata.hfhub_tools.upload.DatasetUpload.save">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="n">dataset</span><span class="p">:</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">local_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save a dataset to a local directory and push it to Hugging Face.</span>
<span class="sd">        Args:</span>
<span class="sd">            dataset (ds.Dataset): Dataset to save and push.</span>
<span class="sd">            local_dir (str): Local directory to save the dataset to.&quot;&quot;&quot;</span>

        <span class="c1"># Save to a local directory</span>
        <span class="n">dataset</span><span class="o">.</span><span class="n">save_to_disk</span><span class="p">(</span><span class="n">local_path</span><span class="p">)</span></div>


<div class="viewcode-block" id="DatasetUpload.push">
<a class="viewcode-back" href="../../../pedata.hfhub_tools.html#pedata.hfhub_tools.upload.DatasetUpload.push">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">push</span><span class="p">(</span><span class="n">dataset</span><span class="p">:</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">repo</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;whole_dataset&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save a dataset to a local directory and push it to Hugging Face.</span>
<span class="sd">        Args:</span>
<span class="sd">            dataset (ds.Dataset): Dataset to save and push.</span>
<span class="sd">            repo (str): Hugging Face Hub repository name (format: &#39;Company/dataset-name&#39;).</span>
<span class="sd">            split (str): The name of the split to push to the hub. Defaults to &quot;whole_dataset&quot;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># push to hub</span>
        <span class="n">dataset</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">(</span>
            <span class="n">repo</span><span class="p">,</span>
            <span class="n">private</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span>
            <span class="n">embed_external_files</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span></div>
</div>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="c1"># parse arguments</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span>
        <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Create and push a dataset to Hugging Face.&quot;</span>
    <span class="p">)</span>
    <span class="c1"># required arguments</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--repo&quot;</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Name of the repository to pull from on Hugging Face.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="c1"># optional arguments</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--commit_hash&quot;</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;str:The commit hash of the dataset to pull from Hugging Face.&quot;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--filename&quot;</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Path to the CSV file for dataset creation.&quot;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--local_dir&quot;</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Name of the local directory to save the dataset to.&quot;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;./local_datasets&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--cache_dir&quot;</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;cache directory&quot;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;./cache&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--save_locally&quot;</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Name of the local directory to save the dataset to.&quot;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--update_just_readme&quot;</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;When update - just update the readme or dataset card.&quot;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--splits_to_combine_as_whole_ds&quot;</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;list: names of the split to combine as &#39;whole_dataset&#39;&quot;</span><span class="p">,</span>
        <span class="n">nargs</span><span class="o">=</span><span class="s2">&quot;+&quot;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="p">[],</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--needed_encodings&quot;</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;list: list of encodings for the dataset; default: []&quot;</span><span class="p">,</span>
        <span class="n">nargs</span><span class="o">=</span><span class="s2">&quot;+&quot;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="p">[],</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--overwrite_repo&quot;</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;bool: Set to True to overwrite a repo when uploading a new dataset, if the repo already exists&quot;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
    <span class="c1"># create dataset upload object</span>
    <span class="n">data_upload</span> <span class="o">=</span> <span class="n">DatasetUpload</span><span class="p">(</span>
        <span class="n">args</span><span class="o">.</span><span class="n">repo</span><span class="p">,</span>
        <span class="n">commit_hash</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">commit_hash</span><span class="p">,</span>
        <span class="n">local_dir</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">local_dir</span><span class="p">,</span>
        <span class="n">cache_dir</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">cache_dir</span><span class="p">,</span>
        <span class="n">csv_filename</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">filename</span><span class="p">,</span>
        <span class="n">save_locally</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">save_locally</span><span class="p">,</span>
        <span class="n">splits_to_combine_as_whole_ds</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">splits_to_combine_as_whole_ds</span><span class="p">,</span>
        <span class="n">update_just_readme</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">update_just_readme</span><span class="p">,</span>
        <span class="n">needed_encodings</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">needed_encodings</span><span class="p">,</span>
        <span class="n">overwrite_repo</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">overwrite_repo</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># process dataset</span>
    <span class="n">data_upload</span><span class="o">.</span><span class="n">process</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># exmaple usage:</span>
    <span class="c1"># python examples/dataset_upload.py --repo Company/test_example_dataset_ha1 --filename examples/datasets/test_example_dataset_ha1.csv</span>
</pre></div>

          </div>
          <div class="page-nav">
            <div class="inner"><ul class="page-nav">
</ul><div class="footer" role="contentinfo">
      &#169; Copyright 2023, Company.
    <br>
    Created using <a href="http://sphinx-doc.org/">Sphinx</a> 7.2.6 with <a href="https://github.com/schettino72/sphinx_press_theme">Press Theme</a> 0.8.0.
</div>
            </div>
          </div>
      </page>
    </div></div>
    
    
  </body>
</html>